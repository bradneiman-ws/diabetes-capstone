{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f552c4",
   "metadata": {},
   "source": [
    "# Diabetes Readmission — Capstone Report\n",
    "\n",
    "**TL;DR:** State the question, data, method, result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a27b3",
   "metadata": {},
   "source": [
    "## 1. Data & Setup\n",
    "- Dataset: add link & license\n",
    "- Task: define target\n",
    "- Ethics: PHI privacy, fairness caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../input/diabetes/diabetes.csv'  # update to your Kaggle dataset path\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except Exception as e:\n",
    "    print('Update csv_path or attach a Kaggle Dataset. Error:', e)\n",
    "    df = None\n",
    "\n",
    "df.head() if df is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930a078",
   "metadata": {},
   "source": [
    "### If using the UCI Hospitals dataset, map `readmitted` → `target` (1 for `<30`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'readmitted' in df.columns:\n",
    "    df['target'] = (df['readmitted'] == '<30').astype(int)\n",
    "elif df is not None and 'Outcome' in df.columns:\n",
    "    df['target'] = df['Outcome'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d94bb7",
   "metadata": {},
   "source": [
    "## 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62befdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    target = 'readmitted' if 'readmitted' in df.columns else df.columns[-1]\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y if y.nunique()<=20 else None)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp if y_temp.nunique()<=20 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91179295",
   "metadata": {},
   "source": [
    "## 3. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ff2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    num_cols = X_train.select_dtypes(include=[float, int, 'number']).columns.tolist()\n",
    "    cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "    pre = ColumnTransformer([\n",
    "        ('num', Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', StandardScaler())]), num_cols),\n",
    "        ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('oh', OneHotEncoder(handle_unknown='ignore'))]), cat_cols)\n",
    "    ])\n",
    "    clf = Pipeline([('pre', pre), ('lr', LogisticRegression(max_iter=200))])\n",
    "    clf.fit(X_train, y_train)\n",
    "    p_valid = clf.predict_proba(X_valid)[:,1]\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    metrics = {\n",
    "        'AUROC': float(roc_auc_score(y_valid, p_valid)),\n",
    "        'AUPRC': float(average_precision_score(y_valid, p_valid)),\n",
    "        'F1': float(f1_score(y_valid, y_pred, average='binary' if y_valid.nunique()==2 else 'macro')),\n",
    "        'Accuracy': float(accuracy_score(y_valid, y_pred)),\n",
    "    }\n",
    "    metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d32d2f",
   "metadata": {},
   "source": [
    "## 4. Error Analysis & Subgroups\n",
    "Add a few cohort slices and discuss errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95791fd9",
   "metadata": {},
   "source": [
    "## 5. Limitations & Next Steps\n",
    "- Data quality, leakage checks\n",
    "- Try stronger models (XGBoost/LightGBM)\n",
    "- Calibrate thresholds to clinical need"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}